%YAML 1.0
---

# Make sure the first entry always works (should run on CPU) -- add new entries at the end of the file.

# It is ok to have duplicate model names as long as <ACCEL>:<TYPE>:<NAME> is unique, where ACCEL is one of (OpenCV, NPU,
# SPU, TPU, VPU, NPUX, VPUX, Python), and TYPE is one of (Classify, Detect, Segment, YuNet, Python, Custom).

# The following keys are used in the JeVois-Pro GUI ('pipe' parameter of Pipeline component):
#
# OpenCV: network loaded by OpenCV DNN framework and running on CPU.
# NPU: network running native on the JeVois-Pro integrated 5-TOPS NPU (neural processing unit).
# TPU: network running on the optional 4-TOPS Google Coral TPU accelerator (tensor processing unit).
# SPU: network running on the optional 26-TOPS Hailo8 SPU accelerator (stream processing unit).
# VPU: network running on the optional 1-TOPS MyriadX VPU accelerator (vector ptocessing unit).
# NPUX: network loaded by OpenCV and run on NPU via the TIM-VX OpenCV extension. To run efficiently, network
#       should have been quantized to int8, otherwise some slow CPU-based emulation will occur.
# VPUX: network optimized for VPU but running on CPU if VPU is not available. Note that VPUX entries are automatically
#       created by scanning all VPU entries and changing their target from Myriad to CPU, if a VPU accelerator is
#       not detected. If a VPU is detected, then VPU models are listed and VPUX ones are not.

# For an up to date list of supported keys in this file, see all the parameters defined in:
#
# jevois/include/jevois/DNN/PreProcessor*.H
# jevois/include/jevois/DNN/Network*.H
# jevois/include/jevois/DNN/PostProcessor*.H
# jevois/include/jevois/DNN/Pipeline.H

# The parameters are all reset to their default values specified in the above files when a new model is loaded, except
# for those of Pipeline. So, no need to set these parameters again here if the default value is acceptable. For example,
# in PostProcessor.H, parameter 'nms' (for non-maximum suppression) defaults to 45.0, so no need to repeat that here if
# that value works for your model. But you can set it here with a different value that may work better for a given
# model.

# Include all YAML files in the /jevoispro/share/dnn/custom/ directory:
includedir: custom

# If we have a hailo board installed, run a hailo model by default. Will be skipped if no Hailo is present:
YOLOv8n-640:
  preproc: Blob
  scale: 1.0
  mean: "0 0 0"
  nettype: SPU
  model: "hailo/detection/yolov8n.hef"
  comment: "Demo model from Hailo"
  url: "https://hailo.ai/devzone-model-zoo/object-detection/"
  postproc: Detect
  detecttype: YOLOv8t
  sigmoid: false
  classes: "dnn/labels/coco-labels.txt"

# Default model to run if there are no custom models and no Hailo-8 board above. On host, which has no NPU, this one
# will be skipped and the first one from the next included file (opencv.yml) will be loaded instead:
yolo11n-512x288-AA:
  preproc: Blob
  mean: "0 0 0"
  scale: 0.0039215686
  nettype: NPU
  model: "npu/detection/yolo11n-512x288.nb"
  library: "npu/detection/libnn_yolo11n-512x288.so"
  comment: "JeVois converted using NPU SDK and Asymmetric Affine quant"
  postproc: Detect
  detecttype: YOLOv8
  nmsperclass: true
  processing: Sync
  classes: "dnn/labels/coco-labels.txt"
  processing: Sync

# Include (recursively) zoo files for various accelerators:
include: opencv.yml
include: npu.yml
include: spu.yml
include: tpu.yml
include: vpu.yml
include: ort.yml

# Note that you can set global parameters, which will be applied, if appropriate, to any pipeline selected. For example,
# if you put all your OpenCV classification networks in one YAML file, you could set this at the beginning:
#
# preproc: Blob
# nettype: OpenCV
# postproc: Classify
#
# and then you do not need to repeat it for every model. Globals apply to the following pipelines only, and to the
# current file only, and they do not combine recursively to/from included files.

# To unset (forget about) a global, use:
#
# unset: name   # e.g., unset: preproc
#
# See vpu.yml for examples. It is not necessary to unset a parameter before you set it to a new value, the new
# value will just replace the old one.

# Finally note that our current preferred organization strategy is that custom models should be under
# /jevoispro/share/dnn/custom/ for their model files, label file, and one .yml file with a single entry for that
# model. When organized in that way, the YAML file for each custom model will show up in the GUI as one of the config
# files you can edit under the "Config" tab.
